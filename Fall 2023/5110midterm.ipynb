{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/youziya/OneDrive - York University/MBAN 5110 Predictive Modelling/Midterm/midterm_partone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters without bias term: [ 5.04816747e-02 -9.41202869e-05 -1.16354477e-01  1.36601795e-03\n",
      " -3.73644421e-02  3.23013255e-02 -1.54543871e-04]\n",
      "Estimated bias term delta: -0.6499832798045937\n",
      "Estimated parameters with bias term: [ 5.04865181e-02 -9.43949281e-05 -1.16353086e-01  1.36617673e-03\n",
      " -3.73482580e-02  3.23108198e-02 -1.53977719e-04]\n"
     ]
    }
   ],
   "source": [
    "# Define the variables\n",
    "Y = df['Stock Change']\n",
    "X = df[['Constant', 'Inventory Turnover', 'Operating Profit', 'Interaction Effect', 'Current Ratio', 'Quick Ratio', 'Debt Asset Ratio']]\n",
    "Z = X  # Assuming that the exogenous variables can serve as instruments\n",
    "\n",
    "# Define the moment conditions function\n",
    "def moment_conditions(params, endog, exog, instruments):\n",
    "    residuals = endog - np.dot(exog, params)\n",
    "    moments = np.dot(instruments.T, residuals)\n",
    "    return moments\n",
    "\n",
    "# Define the GMM objective function\n",
    "def gmm_objective(params, endog, exog, instruments, W):\n",
    "    moms = moment_conditions(params, endog, exog, instruments)\n",
    "    return np.dot(np.dot(moms, W), moms)\n",
    "\n",
    "# Initial weighting matrix as identity\n",
    "initial_W = np.eye(Z.shape[1])\n",
    "\n",
    "# Initial guess for the parameters\n",
    "initial_params = np.zeros(X.shape[1])\n",
    "\n",
    "# Optimization to minimize the GMM objective function\n",
    "res = minimize(\n",
    "    fun=gmm_objective,\n",
    "    x0=initial_params,\n",
    "    args=(Y, X, Z, initial_W),\n",
    "    method='BFGS'\n",
    ")\n",
    "\n",
    "# Estimate the bias term delta as the mean of the product of residuals and instruments\n",
    "estimated_residuals = Y - np.dot(X, res.x)\n",
    "delta_estimate = np.dot(Z.T, estimated_residuals).mean()\n",
    "\n",
    "# Define the biased moment conditions\n",
    "def biased_moment_conditions(params, endog, exog, instruments, delta):\n",
    "    residuals = endog - np.dot(exog, params)\n",
    "    moments = np.dot(instruments.T, residuals) - delta * np.ones(instruments.shape[1])\n",
    "    return moments\n",
    "\n",
    "# Define the GMM objective function including the bias term\n",
    "def gmm_objective_with_bias(params, endog, exog, instruments, W, delta):\n",
    "    moms = biased_moment_conditions(params, endog, exog, instruments, delta)\n",
    "    return np.dot(moms.T, np.dot(W, moms))\n",
    "\n",
    "# Minimize the GMM objective with the bias term included\n",
    "res_with_bias = minimize(\n",
    "    fun=gmm_objective_with_bias,\n",
    "    x0=res.x,  # Use the parameters estimated from the unbiased model as starting values\n",
    "    args=(Y, X, Z, initial_W, delta_estimate),\n",
    "    method='BFGS'\n",
    ")\n",
    "\n",
    "# Output the estimated parameters and the bias term\n",
    "print(\"Estimated parameters without bias term:\", res.x)\n",
    "print(\"Estimated bias term delta:\", delta_estimate)\n",
    "print(\"Estimated parameters with bias term:\", res_with_bias.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/Users/youziya/OneDrive - York University/MBAN 5110 Predictive Modelling/Midterm/midterm_parttwo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 485,   86],\n",
       "        [2846,  624]]),\n",
       " 0.17982708933717578,\n",
       " 0.8788732394366198,\n",
       " 0.2985645933014354,\n",
       " 0.8785019080284596)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# One-hot encode the categorical variables\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' to avoid dummy variable trap\n",
    "categorical_columns = ['Requested Credit Amount', 'Number of Dependents', 'Monthly Income', 'Monthly Expense', 'Marital Status']\n",
    "X_categorical = encoder.fit_transform(df2[categorical_columns])\n",
    "\n",
    "# Combine the one-hot encoded columns with the continuous ones\n",
    "X_continuous = df2[['Years of Education after High School']].values\n",
    "X = np.hstack((X_continuous, X_categorical))\n",
    "\n",
    "# Convert the target variable 'Credit Rating' into binary (0, 1)\n",
    "Y = (df2['Credit Rating'] == 'Positive').astype(int).values\n",
    "\n",
    "# Split the data into training (50%) and test (50%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Fit the logistic regression model on the training set\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the Credit Rating on the test set\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix, recall, precision, and F1 score\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Get the predicted probabilities for the positive class (1)\n",
    "Y_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find the threshold that will result in 15% of applications being approved\n",
    "threshold_15_percent = np.percentile(Y_probs, 85)  # 100% - 15% = 85%\n",
    "\n",
    "# Apply the new threshold to determine credit approvals\n",
    "Y_pred_adjusted = (Y_probs >= threshold_15_percent).astype(int)\n",
    "\n",
    "# Calculate the new confusion matrix, recall, precision, and F1 score with the adjusted threshold\n",
    "conf_matrix_adjusted = confusion_matrix(Y_test, Y_pred_adjusted)\n",
    "recall_adjusted = recall_score(Y_test, Y_pred_adjusted)\n",
    "precision_adjusted = precision_score(Y_test, Y_pred_adjusted)\n",
    "f1_adjusted = f1_score(Y_test, Y_pred_adjusted)\n",
    "\n",
    "# Output the new evaluation metrics with the adjusted threshold\n",
    "(conf_matrix_adjusted, recall_adjusted, precision_adjusted, f1_adjusted, threshold_15_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Bank Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Confusion Matrix': [[0, 571], [0, 3470]],\n",
       "  'Recall': 1.0,\n",
       "  'Precision': 0.8586983419945559,\n",
       "  'F1 Score': 0.9239781653574758},\n",
       " {'Confusion Matrix': [[485, 86], [2846, 624]],\n",
       "  'Recall': 0.17982708933717578,\n",
       "  'Precision': 0.8788732394366198,\n",
       "  'F1 Score': 0.2985645933014354,\n",
       "  'Threshold': 0.8785019080284596})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# One-hot encode the categorical variables\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # Avoid dummy variable trap\n",
    "categorical_columns = ['Requested Credit Amount', 'Number of Dependents', \n",
    "                       'Monthly Income', 'Monthly Expense', 'Marital Status']\n",
    "X_categorical = encoder.fit_transform(df2[categorical_columns])\n",
    "\n",
    "# Combine the one-hot encoded columns with the continuous ones\n",
    "X_continuous = df2[['Years of Education after High School']].values\n",
    "X = np.hstack((X_continuous, X_categorical))\n",
    "\n",
    "# Convert the target variable 'Credit Rating' to binary (0, 1)\n",
    "Y = (df2['Credit Rating'] == 'Positive').astype(int).values\n",
    "\n",
    "# Split the data into training (50%) and test (50%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Fit the logistic regression model on the training set\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the Credit Rating on the test set using the default threshold\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix, recall, precision, and F1 score\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Get the predicted probabilities for the positive class (1)\n",
    "Y_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find the threshold that results in 15% of applications being approved\n",
    "threshold_15_percent = np.percentile(Y_probs, 85)  # 100% - 15% = 85%\n",
    "\n",
    "# Apply the new threshold to determine credit approvals\n",
    "Y_pred_adjusted = (Y_probs >= threshold_15_percent).astype(int)\n",
    "\n",
    "# Calculate the new confusion matrix, recall, precision, and F1 score with the adjusted threshold\n",
    "conf_matrix_adjusted = confusion_matrix(Y_test, Y_pred_adjusted)\n",
    "recall_adjusted = recall_score(Y_test, Y_pred_adjusted)\n",
    "precision_adjusted = precision_score(Y_test, Y_pred_adjusted)\n",
    "f1_adjusted = f1_score(Y_test, Y_pred_adjusted)\n",
    "\n",
    "# Output the new evaluation metrics with the adjusted threshold\n",
    "original_metrics = {\n",
    "    \"Confusion Matrix\": conf_matrix.tolist(),\n",
    "    \"Recall\": recall,\n",
    "    \"Precision\": precision,\n",
    "    \"F1 Score\": f1\n",
    "}\n",
    "\n",
    "adjusted_metrics = {\n",
    "    \"Confusion Matrix\": conf_matrix_adjusted.tolist(),\n",
    "    \"Recall\": recall_adjusted,\n",
    "    \"Precision\": precision_adjusted,\n",
    "    \"F1 Score\": f1_adjusted,\n",
    "    \"Threshold\": threshold_15_percent\n",
    "}\n",
    "\n",
    "original_metrics, adjusted_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
