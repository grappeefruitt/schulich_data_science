{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS \n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/youziya/OneDrive - York University/MBAN 5110 Predictive Modelling/Midterm/midterm_partone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Constant</th>\n",
       "      <th>Stock Change</th>\n",
       "      <th>Inventory Turnover</th>\n",
       "      <th>Operating Profit</th>\n",
       "      <th>Interaction Effect</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Debt Asset Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.870332</td>\n",
       "      <td>1.795946</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>0.208053</td>\n",
       "      <td>1.672527</td>\n",
       "      <td>0.255171</td>\n",
       "      <td>0.473317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.047347</td>\n",
       "      <td>1.395501</td>\n",
       "      <td>0.436967</td>\n",
       "      <td>0.609788</td>\n",
       "      <td>1.637261</td>\n",
       "      <td>0.221763</td>\n",
       "      <td>0.489967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1.664563</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.900555</td>\n",
       "      <td>1.640619</td>\n",
       "      <td>0.189141</td>\n",
       "      <td>0.374269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.901200</td>\n",
       "      <td>1.605738</td>\n",
       "      <td>0.539399</td>\n",
       "      <td>0.866133</td>\n",
       "      <td>1.436221</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.224399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.176353</td>\n",
       "      <td>1.591451</td>\n",
       "      <td>0.539938</td>\n",
       "      <td>0.859285</td>\n",
       "      <td>1.433140</td>\n",
       "      <td>0.183095</td>\n",
       "      <td>0.213446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Constant  Stock Change  Inventory Turnover  Operating Profit  \\\n",
       "0         1      0.870332            1.795946          0.115846   \n",
       "1         1     -0.047347            1.395501          0.436967   \n",
       "2         1      0.001176            1.664563          0.541016   \n",
       "3         1     -0.901200            1.605738          0.539399   \n",
       "4         1     -0.176353            1.591451          0.539938   \n",
       "\n",
       "   Interaction Effect  Current Ratio  Quick Ratio  Debt Asset Ratio  \n",
       "0            0.208053       1.672527     0.255171          0.473317  \n",
       "1            0.609788       1.637261     0.221763          0.489967  \n",
       "2            0.900555       1.640619     0.189141          0.374269  \n",
       "3            0.866133       1.436221     0.131944          0.224399  \n",
       "4            0.859285       1.433140     0.183095          0.213446  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the ols regression\n",
    "model_iv = sm.OLS(df[\"Inventory Turnover\"],df[[\"Constant\",\"Current Ratio\",\"Quick Ratio\",\\\n",
    "                                                                 \"Debt Asset Ratio\"]]).fit()\n",
    "#making predictions, note that only the independent variables are in predictions \n",
    "endog_predict = model_iv.predict(df[[\"Constant\",\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])\n",
    "#adding predictions to data table\n",
    "df[\"Endogenous Param\"] = endog_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Stock Change</td>   <th>  R-squared:         </th> <td>   0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>1.27e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:19:16</td>     <th>  Log-Likelihood:    </th> <td> -1186.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>  AIC:               </th> <td>   2381.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1692</td>      <th>  BIC:               </th> <td>   2403.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Constant</th>           <td>   -0.0176</td> <td>    0.020</td> <td>   -0.896</td> <td> 0.370</td> <td>   -0.056</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Endogenous Param</th>   <td>    0.0011</td> <td>    0.001</td> <td>    1.827</td> <td> 0.068</td> <td>-7.76e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Operating Profit</th>   <td>   -0.1201</td> <td>    0.028</td> <td>   -4.319</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interaction Effect</th> <td>    0.0014</td> <td>    0.000</td> <td>    3.621</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>368.832</td> <th>  Durbin-Watson:     </th> <td>   2.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3433.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.742</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.811</td>  <th>  Cond. No.          </th> <td>    109.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Stock Change   R-squared:                       0.015\n",
       "Model:                            OLS   Adj. R-squared:                  0.013\n",
       "Method:                 Least Squares   F-statistic:                     8.530\n",
       "Date:                Sat, 11 Nov 2023   Prob (F-statistic):           1.27e-05\n",
       "Time:                        18:19:16   Log-Likelihood:                -1186.5\n",
       "No. Observations:                1696   AIC:                             2381.\n",
       "Df Residuals:                    1692   BIC:                             2403.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Constant              -0.0176      0.020     -0.896      0.370      -0.056       0.021\n",
       "Endogenous Param       0.0011      0.001      1.827      0.068   -7.76e-05       0.002\n",
       "Operating Profit      -0.1201      0.028     -4.319      0.000      -0.175      -0.066\n",
       "Interaction Effect     0.0014      0.000      3.621      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      368.832   Durbin-Watson:                   2.243\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3433.920\n",
       "Skew:                           0.742   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.811   Cond. No.                         109.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2sls = sm.OLS(df[\"Stock Change\"], df[[\"Constant\",\"Endogenous Param\",\\\n",
    "                                                              \"Operating Profit\",\"Interaction Effect\",\\\n",
    "                                                             ]]).fit()\n",
    "model_2sls.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals  = np.array(df[\"Stock Change\"])\n",
    "x_vals  = np.array(df[[\"Inventory Turnover\",\"Operating Profit\",\"Interaction Effect\"]])\n",
    "iv_vals = np.array(df[[\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000007\n",
      "         Iterations: 9\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000167\n",
      "         Iterations: 7\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000142\n",
      "         Iterations: 19\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000143\n",
      "         Iterations: 6\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000143\n",
      "         Iterations: 2\n",
      "         Function evaluations: 4\n",
      "         Gradient evaluations: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>gmm Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>  0.2426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>gmm</td>       <th>  Prob (Hansen J):   </th>  <td> 0.622</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:19:16</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 0</th> <td>   -0.2038</td> <td>    0.193</td> <td>   -1.056</td> <td> 0.291</td> <td>   -0.582</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 1</th> <td>    0.0046</td> <td>    0.004</td> <td>    1.091</td> <td> 0.275</td> <td>   -0.004</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 2</th> <td>    0.6549</td> <td>    0.769</td> <td>    0.852</td> <td> 0.394</td> <td>   -0.852</td> <td>    2.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 3</th> <td>   -0.0143</td> <td>    0.017</td> <td>   -0.844</td> <td> 0.399</td> <td>   -0.047</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 4</th> <td>    0.0071</td> <td>    0.005</td> <td>    1.423</td> <td> 0.155</td> <td>   -0.003</td> <td>    0.017</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 gmm Results                                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                       0.2426\n",
       "Model:                            gmm   Prob (Hansen J):                 0.622\n",
       "Method:                           GMM                                         \n",
       "Date:                Sat, 11 Nov 2023                                         \n",
       "Time:                        18:19:16                                         \n",
       "No. Observations:                1696                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "p 0           -0.2038      0.193     -1.056      0.291      -0.582       0.174\n",
       "p 1            0.0046      0.004      1.091      0.275      -0.004       0.013\n",
       "p 2            0.6549      0.769      0.852      0.394      -0.852       2.161\n",
       "p 3           -0.0143      0.017     -0.844      0.399      -0.047       0.019\n",
       "p 4            0.0071      0.005      1.423      0.155      -0.003       0.017\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class gmm(GMM):\n",
    "    def momcond(self, params):\n",
    "        # Now includes delta as the last parameter\n",
    "        p0, p1, p2, p3, delta = params\n",
    "        endog = self.endog\n",
    "        exog = self.exog\n",
    "        inst = self.instrument\n",
    "\n",
    "        # Calculate errors\n",
    "        errors = endog - p0 - p1 * exog[:, 0] - p2 * exog[:, 1] - p3 * exog[:, 2]\n",
    "        \n",
    "        # Adjust moment conditions for delta\n",
    "        g = np.column_stack((\n",
    "            errors - delta,\n",
    "            errors * exog[:, 0] - delta,\n",
    "            errors * exog[:, 1] - delta,\n",
    "            errors * inst[:, 0] - delta,\n",
    "            errors * inst[:, 1] - delta,\n",
    "            errors * inst[:, 2] - delta\n",
    "        ))\n",
    "        return g\n",
    "\n",
    "# Update the initial values for the parameters, including delta\n",
    "beta0 = np.array([0.1, 0.1, 0.1, 0.1, 0.1])  # Added an initial guess for delta\n",
    "\n",
    "# Fit the model\n",
    "res = gmm(endog=y_vals, exog=x_vals, instrument=iv_vals, k_moms=6, k_params=5).fit(beta0)\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000101\n",
      "         Iterations: 5\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001766\n",
      "         Iterations: 8\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001744\n",
      "         Iterations: 6\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001744\n",
      "         Iterations: 1\n",
      "         Function evaluations: 3\n",
      "         Gradient evaluations: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>gmm Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>   2.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>gmm</td>       <th>  Prob (Hansen J):   </th>  <td> 0.228</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:21:11</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 0</th> <td>   -0.0006</td> <td> 8.15e+05</td> <td>-7.02e-10</td> <td> 1.000</td> <td> -1.6e+06</td> <td>  1.6e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 1</th> <td>    0.0004</td> <td>    0.000</td> <td>    1.024</td> <td> 0.306</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 2</th> <td>   -0.1188</td> <td>    0.031</td> <td>   -3.861</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 3</th> <td>    0.0014</td> <td>    0.000</td> <td>    3.645</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 4</th> <td>   -0.0006</td> <td> 8.15e+05</td> <td>-7.02e-10</td> <td> 1.000</td> <td> -1.6e+06</td> <td>  1.6e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 gmm Results                                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                        2.958\n",
       "Model:                            gmm   Prob (Hansen J):                 0.228\n",
       "Method:                           GMM                                         \n",
       "Date:                Sat, 11 Nov 2023                                         \n",
       "Time:                        18:21:11                                         \n",
       "No. Observations:                1696                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "p 0           -0.0006   8.15e+05  -7.02e-10      1.000    -1.6e+06     1.6e+06\n",
       "p 1            0.0004      0.000      1.024      0.306      -0.000       0.001\n",
       "p 2           -0.1188      0.031     -3.861      0.000      -0.179      -0.059\n",
       "p 3            0.0014      0.000      3.645      0.000       0.001       0.002\n",
       "p 4           -0.0006   8.15e+05  -7.02e-10      1.000    -1.6e+06     1.6e+06\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class gmm(GMM):\n",
    "    def momcond(self, params):\n",
    "        # Include delta as the last parameter\n",
    "        p0, p1, p2, p3, delta = params\n",
    "        endog = self.endog\n",
    "        exog = self.exog\n",
    "        inst = self.instrument   \n",
    "\n",
    "        # Calculate errors\n",
    "        errors = endog - p0 - p1 * exog[:, 0] - p2 * exog[:, 1] - p3 * exog[:, 2]\n",
    "\n",
    "        # Adjust moment conditions with the delta term\n",
    "        g = np.column_stack((\n",
    "            errors - delta,\n",
    "            (errors - delta) * exog[:, 0],\n",
    "            (errors - delta) * exog[:, 1],\n",
    "            (errors - delta) * exog[:, 2],\n",
    "            (errors - delta) * inst[:, 0],\n",
    "            (errors - delta) * inst[:, 1],\n",
    "            (errors - delta) * inst[:, 2]\n",
    "        ))\n",
    "        return g\n",
    "\n",
    "# Update the initial values for the parameters, including delta\n",
    "beta0 = np.array([0.1, 0.1, 0.1, 0.1, 0.1])  # Added an initial guess for delta\n",
    "\n",
    "# Fit the model\n",
    "res = gmm(endog=y_vals, exog=x_vals, instrument=iv_vals, k_moms=7, k_params=5).fit(beta0)\n",
    "\n",
    "res.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000101\n",
      "         Iterations: 5\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001766\n",
      "         Iterations: 8\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001744\n",
      "         Iterations: 6\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001744\n",
      "         Iterations: 1\n",
      "         Function evaluations: 3\n",
      "         Gradient evaluations: 3\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/grappeefruitt/schulich_data_science/Fall 2023/5110midterm.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://github/grappeefruitt/schulich_data_science/Fall%202023/5110midterm.ipynb#X33sdnNjb2RlLXZmcw%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Create and fit the GMM model with delta term\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://github/grappeefruitt/schulich_data_science/Fall%202023/5110midterm.ipynb#X33sdnNjb2RlLXZmcw%3D%3D?line=28'>29</a>\u001b[0m model_with_delta \u001b[39m=\u001b[39m gmm_with_delta(endog\u001b[39m=\u001b[39my_vals, exog\u001b[39m=\u001b[39mx_vals, instrument\u001b[39m=\u001b[39miv_vals, k_moms\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, k_params\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://github/grappeefruitt/schulich_data_science/Fall%202023/5110midterm.ipynb#X33sdnNjb2RlLXZmcw%3D%3D?line=29'>30</a>\u001b[0m results_with_delta \u001b[39m=\u001b[39m model_with_delta\u001b[39m.\u001b[39;49mfit(initial_params_with_delta)\n\u001b[1;32m     <a href='vscode-notebook-cell://github/grappeefruitt/schulich_data_science/Fall%202023/5110midterm.ipynb#X33sdnNjb2RlLXZmcw%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Display the summary of the results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://github/grappeefruitt/schulich_data_science/Fall%202023/5110midterm.ipynb#X33sdnNjb2RlLXZmcw%3D%3D?line=32'>33</a>\u001b[0m results_with_delta\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/statsmodels/sandbox/regression/gmm.py:697\u001b[0m, in \u001b[0;36mGMM.fit\u001b[0;34m(self, start_params, maxiter, inv_weights, weights_method, wargs, has_optimal_weights, optim_method, optim_args)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m# check that we have the right number of xnames\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fix_param_names(params, param_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 697\u001b[0m results \u001b[39m=\u001b[39m results_class_dict[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresults_class](\n\u001b[1;32m    698\u001b[0m                                 model \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    699\u001b[0m                                 params \u001b[39m=\u001b[39;49m params,\n\u001b[1;32m    700\u001b[0m                                 weights \u001b[39m=\u001b[39;49m weights,\n\u001b[1;32m    701\u001b[0m                                 wargs \u001b[39m=\u001b[39;49m wargs,\n\u001b[1;32m    702\u001b[0m                                 options_other \u001b[39m=\u001b[39;49m options_other,\n\u001b[1;32m    703\u001b[0m                                 optim_args \u001b[39m=\u001b[39;49m optim_args)\n\u001b[1;32m    705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m results \u001b[39m# FIXME: remove, still keeping it temporarily\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/statsmodels/sandbox/regression/gmm.py:1132\u001b[0m, in \u001b[0;36mGMMResults.__init__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnobs\n\u001b[1;32m   1130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_resid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minf\n\u001b[0;32m-> 1132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_params_default \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cov_params()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/statsmodels/sandbox/regression/gmm.py:1165\u001b[0m, in \u001b[0;36mGMMResults._cov_params\u001b[0;34m(self, **kwds)\u001b[0m\n\u001b[1;32m   1163\u001b[0m gradmoms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgradient_momcond(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m   1164\u001b[0m moms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmomcond(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m-> 1165\u001b[0m covparams \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_cov_params(moms, gradmoms, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1167\u001b[0m \u001b[39mreturn\u001b[39;00m covparams\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/statsmodels/sandbox/regression/gmm.py:1212\u001b[0m, in \u001b[0;36mGMMResults.calc_cov_params\u001b[0;34m(self, moms, gradmoms, weights, use_weights, has_optimal_weights, weights_method, wargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     omegahat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcalc_weightmatrix(\n\u001b[1;32m   1204\u001b[0m                                         moms,\n\u001b[1;32m   1205\u001b[0m                                         weights_method\u001b[39m=\u001b[39mweights_method,\n\u001b[1;32m   1206\u001b[0m                                         wargs\u001b[39m=\u001b[39mwargs,\n\u001b[1;32m   1207\u001b[0m                                         params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m   1210\u001b[0m \u001b[39mif\u001b[39;00m has_optimal_weights: \u001b[39m#has_optimal_weights:\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[39m# TOD0 make has_optimal_weights depend on convergence or iter >2\u001b[39;00m\n\u001b[0;32m-> 1212\u001b[0m     cov \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(np\u001b[39m.\u001b[39;49mdot(gradmoms\u001b[39m.\u001b[39;49mT,\n\u001b[1;32m   1213\u001b[0m                             np\u001b[39m.\u001b[39;49mdot(np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(omegahat), gradmoms)))\n\u001b[1;32m   1214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1215\u001b[0m     gw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(gradmoms\u001b[39m.\u001b[39mT, weights)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    562\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "class gmm_with_delta(GMM):\n",
    "    def momcond(self, params):\n",
    "        # Unpack parameters, including delta as the last parameter\n",
    "        p0, p1, p2, p3, delta = params\n",
    "        endog = self.endog\n",
    "        exog = self.exog\n",
    "        inst = self.instrument\n",
    "\n",
    "        # Adjusted errors to include delta term\n",
    "        errors = endog - (p0 + p1 * exog[:, 0] + p2 * exog[:, 1] + p3 * exog[:, 2]) - delta\n",
    "\n",
    "        # Adjusted moment conditions with delta term\n",
    "        g = np.column_stack((\n",
    "            errors,\n",
    "            errors * exog[:, 0],\n",
    "            errors * exog[:, 1],\n",
    "            errors * exog[:, 2],\n",
    "            errors * inst[:, 0],\n",
    "            errors * inst[:, 1],\n",
    "            errors * inst[:, 2]\n",
    "        ))\n",
    "        return g\n",
    "\n",
    "# Initial guesses for the parameters, including delta\n",
    "# 4 original parameters + 1 delta\n",
    "initial_params_with_delta = np.array([0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "# Create and fit the GMM model with delta term\n",
    "model_with_delta = gmm_with_delta(endog=y_vals, exog=x_vals, instrument=iv_vals, k_moms=7, k_params=5)\n",
    "results_with_delta = model_with_delta.fit(initial_params_with_delta)\n",
    "\n",
    "# Display the summary of the results\n",
    "results_with_delta.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hansen J Statistic and its Probability:\n",
    "\n",
    "The Hansen J statistic value is 0.2426, and the probability (p-value) associated with it is 0.622.\n",
    "This high p-value (greater than the conventional threshold of 0.05) suggests that we cannot reject the null hypothesis of the validity of the instrumental variables. In simpler terms, the instruments appear to be appropriate for the model.\n",
    "Coefficient Estimates:\n",
    "\n",
    "The coefficients (p0, p1, p2, p3, p4) have been estimated with their respective standard errors and z-scores.\n",
    "None of the coefficients appear to be statistically significant at conventional levels (e.g., 0.05) since all the p-values associated with them are greater than this threshold.\n",
    "Interpretation of the Coefficients:\n",
    "\n",
    "The coefficients represent the estimated impact of each variable (and potentially the bias \n",
    "�\n",
    "δ) on the dependent variable \n",
    "�\n",
    "y.\n",
    "The lack of statistical significance suggests that the data does not provide strong evidence to confirm the relationships modeled between these variables and the dependent variable.\n",
    "Industry Expert's Claim:\n",
    "\n",
    "The expert's claim was that there is a bias in the moment conditions, represented as \n",
    "�\n",
    "δ in the equation \n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "−\n",
    "�\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "[\n",
    "1\n",
    ",\n",
    "1\n",
    ",\n",
    "1\n",
    "]\n",
    "Z \n",
    "T\n",
    " (Y−XB)=δ[1,1,1], where \n",
    "�\n",
    "δ has a non-zero value.\n",
    "The fact that the Hansen J test does not reject the null hypothesis and that the coefficients, including the term for \n",
    "�\n",
    "δ, are not statistically significant, suggests that the data does not strongly support the expert's claim of a bias.\n",
    "Considerations:\n",
    "\n",
    "The results should be interpreted with caution, as the lack of statistical significance could also be due to other factors such as insufficient sample size, poor model specification, or weak instruments.\n",
    "It's also important to consider the context and theoretical foundation of the model. If the expert's claim about the bias has a strong theoretical basis, it might still be worth considering despite the statistical results.\n",
    "In summary, based on the GMM results, the data does not provide strong evidence to support the industry expert's claim of a bias in the moment conditions. However, careful consideration of the model specification, the validity of the instruments, and the theoretical underpinnings of the claim is essential before drawing a firm conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/Users/youziya/OneDrive - York University/MBAN 5110 Predictive Modelling/Midterm/midterm_parttwo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years of Education after High School</th>\n",
       "      <th>Requested Credit Amount</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Monthly Expense</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Credit Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Married</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Married</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years of Education after High School Requested Credit Amount  \\\n",
       "0                                     1                     Low   \n",
       "1                                     2                     Low   \n",
       "2                                     1                     Low   \n",
       "3                                     3                     Low   \n",
       "4                                     3                     Low   \n",
       "\n",
       "  Number of Dependents Monthly Income Monthly Expense Marital Status  \\\n",
       "0         No dependent       Very low        Very low        Married   \n",
       "1         No dependent       Very low        Very low         Single   \n",
       "2         No dependent       Very low        Very low         Single   \n",
       "3         No dependent       Very low        Very low        Married   \n",
       "4         No dependent       Very low        Very low         Single   \n",
       "\n",
       "  Credit Rating  \n",
       "0      Positive  \n",
       "1      Positive  \n",
       "2      Positive  \n",
       "3      Positive  \n",
       "4      Negative  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the 'Credit Rating' column\n",
    "credit_rating_encoded = pd.get_dummies(df2['Credit Rating'], drop_first=True)\n",
    "data_parttwo_encoded = pd.concat([df2.drop('Credit Rating', axis=1), credit_rating_encoded], axis=1)\n",
    "\n",
    "# Assuming the rest of the data preprocessing (encoding other categorical variables) is done\n",
    "\n",
    "# Defining X (features) and y (target)\n",
    "X = pd.concat([data_parttwo.drop(categorical_cols + ['Credit Rating'], axis=1), encoded_categorical_df], axis=1)\n",
    "\n",
    "# Splitting the dataset into training (50%) and test (50%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Rest of the logistic regression code follows...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parttwo_encoded['Credit Rating'] = data_parttwo_encoded['Credit Rating'].map({'Positive': 1, 'Negative': 0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "log_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training (50%) and test (50%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Fitting a logistic regression model with class weights adjusted for imbalance\n",
    "log_reg_balanced = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_reg_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_balanced = log_reg_balanced.predict(X_test)\n",
    "\n",
    "# Confusion Matrix, Recall, Precision, and F1 Score for the adjusted model\n",
    "conf_matrix_balanced = confusion_matrix(y_test, y_pred_balanced)\n",
    "recall_balanced = recall_score(y_test, y_pred_balanced)\n",
    "precision_balanced = precision_score(y_test, y_pred_balanced)\n",
    "f1_balanced = f1_score(y_test, y_pred_balanced)\n",
    "\n",
    "# Display the results\n",
    "print(\"Confusion Matrix:\", conf_matrix_balanced)\n",
    "print(\"Recall:\", recall_balanced)\n",
    "print(\"Precision:\", precision_balanced)\n",
    "print(\"F1 Score:\", f1_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode the categorical variables\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' to avoid dummy variable trap\n",
    "categorical_columns = ['Requested Credit Amount', 'Number of Dependents', 'Monthly Income', 'Monthly Expense', 'Marital Status']\n",
    "X_categorical = encoder.fit_transform(df2[categorical_columns])\n",
    "\n",
    "# Combine the one-hot encoded columns with the continuous ones\n",
    "X_continuous = df2[['Years of Education after High School']].values\n",
    "X = np.hstack((X_continuous, X_categorical))\n",
    "\n",
    "# Convert the target variable 'Credit Rating' into binary (0, 1)\n",
    "Y = (df2['Credit Rating'] == 'Positive').astype(int).values\n",
    "\n",
    "# Split the data into training (50%) and test (50%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Fit the logistic regression model on the training set\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the Credit Rating on the test set\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix, recall, precision, and F1 score\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Get the predicted probabilities for the positive class (1)\n",
    "Y_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find the threshold that will result in 15% of applications being approved\n",
    "threshold_15_percent = np.percentile(Y_probs, 85)  # 100% - 15% = 85%\n",
    "\n",
    "# Apply the new threshold to determine credit approvals\n",
    "Y_pred_adjusted = (Y_probs >= threshold_15_percent).astype(int)\n",
    "\n",
    "# Calculate the new confusion matrix, recall, precision, and F1 score with the adjusted threshold\n",
    "conf_matrix_adjusted = confusion_matrix(Y_test, Y_pred_adjusted)\n",
    "recall_adjusted = recall_score(Y_test, Y_pred_adjusted)\n",
    "precision_adjusted = precision_score(Y_test, Y_pred_adjusted)\n",
    "f1_adjusted = f1_score(Y_test, Y_pred_adjusted)\n",
    "\n",
    "# Output the new evaluation metrics with the adjusted threshold\n",
    "(conf_matrix_adjusted, recall_adjusted, precision_adjusted, f1_adjusted, threshold_15_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Bank Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode the categorical variables\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # Avoid dummy variable trap\n",
    "categorical_columns = ['Requested Credit Amount', 'Number of Dependents', \n",
    "                       'Monthly Income', 'Monthly Expense', 'Marital Status']\n",
    "X_categorical = encoder.fit_transform(df2[categorical_columns])\n",
    "\n",
    "# Combine the one-hot encoded columns with the continuous ones\n",
    "X_continuous = df2[['Years of Education after High School']].values\n",
    "X = np.hstack((X_continuous, X_categorical))\n",
    "\n",
    "# Convert the target variable 'Credit Rating' to binary (0, 1)\n",
    "Y = (df2['Credit Rating'] == 'Positive').astype(int).values\n",
    "\n",
    "# Split the data into training (50%) and test (50%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Fit the logistic regression model on the training set\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the Credit Rating on the test set using the default threshold\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix, recall, precision, and F1 score\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Get the predicted probabilities for the positive class (1)\n",
    "Y_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find the threshold that results in 15% of applications being approved\n",
    "threshold_15_percent = np.percentile(Y_probs, 85)  # 100% - 15% = 85%\n",
    "\n",
    "# Apply the new threshold to determine credit approvals\n",
    "Y_pred_adjusted = (Y_probs >= threshold_15_percent).astype(int)\n",
    "\n",
    "# Calculate the new confusion matrix, recall, precision, and F1 score with the adjusted threshold\n",
    "conf_matrix_adjusted = confusion_matrix(Y_test, Y_pred_adjusted)\n",
    "recall_adjusted = recall_score(Y_test, Y_pred_adjusted)\n",
    "precision_adjusted = precision_score(Y_test, Y_pred_adjusted)\n",
    "f1_adjusted = f1_score(Y_test, Y_pred_adjusted)\n",
    "\n",
    "# Output the new evaluation metrics with the adjusted threshold\n",
    "original_metrics = {\n",
    "    \"Confusion Matrix\": conf_matrix.tolist(),\n",
    "    \"Recall\": recall,\n",
    "    \"Precision\": precision,\n",
    "    \"F1 Score\": f1\n",
    "}\n",
    "\n",
    "adjusted_metrics = {\n",
    "    \"Confusion Matrix\": conf_matrix_adjusted.tolist(),\n",
    "    \"Recall\": recall_adjusted,\n",
    "    \"Precision\": precision_adjusted,\n",
    "    \"F1 Score\": f1_adjusted,\n",
    "    \"Threshold\": threshold_15_percent\n",
    "}\n",
    "\n",
    "original_metrics, adjusted_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
