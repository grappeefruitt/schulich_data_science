{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time # to measure how long the models take\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/Users/youziya/Downloads/test.csv', sep=\";\")\n",
    "train = pd.read_csv('/Users/youziya/Downloads/train.csv', sep=\";\")\n",
    "df = pd.concat([test,train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df.drop(['contact','day','month','pdays','poutcome'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_summary = df.describe()\n",
    "\n",
    "# Exploring the unique values of some of the categorical variables\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "categorical_values = {column: train_data[column].unique() for column in categorical_columns}\n",
    "\n",
    "numerical_summary, categorical_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x = df['y'])\n",
    "plt.title('Box Plot of Data with Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df[df['Value'] <= ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df.duplicated(subset=df.columns.difference(['age','y','job','marital','education'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicate_rows = duplicate_rows.sum() \n",
    "num_duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['age', 'balance', 'duration', 'campaign', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=['int64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Distribution of categorical features\n",
    "    sns.countplot(data=df, x=feature, hue='y')\n",
    "    plt.title(f'{feature.capitalize()} Distribution by Subscription', fontsize=15)\n",
    "    plt.xlabel(feature.capitalize(), fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=df[feature])\n",
    "    plt.title(f'Boxplot of {feature.capitalize()}', fontsize=15)\n",
    "    plt.xlabel(feature.capitalize(), fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot\n",
    "sns.boxplot(x=\"day\", y=\"total_bill\", data=data)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Total Bill Amount\")\n",
    "plt.title(\"Box Plot of Total Bill Amount by Day\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats = df.describe()\n",
    "print(descriptive_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"y\"]\n",
    "X = df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "num_cols = X.select_dtypes(include=['int64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(), cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth=20)\n",
    "\n",
    "# Create the BaggingClassifier with the specified base estimator\n",
    "bag = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up models to compare - I am adding some initial parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "log_reg = LogisticRegression(C=0.1)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "bag = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "voting = VotingClassifier(estimators=[('knn', knn), ('bag', bag), ('lr', log_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'K-Nearest Neighbors': knn,\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Random Forest': rf,\n",
    "    'AdaBoost': ada,\n",
    "    'Bagging': bag,\n",
    "    'Voting': voting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop through list of models to compare performance\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', clf)])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_true = y_test\n",
    "    y_pred = pipeline.predict(X_test) \n",
    "\n",
    "    # Compute metrics\n",
    "    precision = precision_score(y_true, y_pred, pos_label='yes')\n",
    "    recall = recall_score(y_true, y_pred, pos_label='yes')\n",
    "    f1 = f1_score(y_true, y_pred, pos_label='yes')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Time (s)': elapsed_time\n",
    "    }\n",
    "\n",
    "# Convert results to DataFrame for easier viewing\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "### The knn methos is one of the most inefficient one as it takes longer time to process. Its precision score is high and recall score is low meaning that it correcly identiies how many people subscirbe but missess a significant number of actual subscribers. \n",
    "### The logisitc regression is the most efficent model as it takes the least time. The overall perforamnce is good but not he best.\n",
    "### Random Forest model overall performance is good even though it takes 11 seconds.\n",
    "### Ada Boost is faster than knn but slower than logistic regressionn. Its F1 score and accuracy is similar to logistic regresssion.\n",
    "### Bagging method is relatively efficient one as it takes 6 seconds. Its precison score and recall score is overalll good however it means\n",
    "### Voting method is the most inefficent one as it takes 40 seconds. Its performance is not good either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base estimator (e.g., DecisionTreeClassifier)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=20)\n",
    "\n",
    "# Create the BaggingClassifier with the specified base estimator\n",
    "bag = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up models to compare - I am adding some initial parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "log_reg = LogisticRegression(penalty='l2',\n",
    "    C=0.1,    \n",
    "    solver='liblinear',\n",
    "    max_iter=100,  \n",
    "    multi_class='ovr',\n",
    "    class_weight='balanced')\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "bag = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "voting = VotingClassifier(estimators=[('knn', knn), ('bag', bag), ('lr', log_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier({'n_neighbors': [5, 10, 15]})\n",
    "log_reg = LogisticRegression({'C': [0.001, 0.01, 0.1, 1, 10]})\n",
    "rf = RandomForestClassifier({'n_estimators': [50, 100, 200]})\n",
    "ada = AdaBoostClassifier({'n_estimators': [50, 100, 200]})\n",
    "bag = BaggingClassifier({'n_estimators': [10, 50, 100]})\n",
    "voting = VotingClassifier(estimators=[('lr', log_reg), ('knn', knn), ('rf', rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grids for tuning\n",
    "knn_params = {'classifier__n_neighbors': [3, 5, 7, 20, 30, 50, 100]}\n",
    "log_reg_params = {'classifier__C': [0.1, 1, 10]}\n",
    "rf_params = {'classifier__n_estimators': [50, 100, 150], 'classifier__max_depth': [None, 10, 20, 30, 50]}\n",
    "ada_params = {'classifier__n_estimators': [25, 50, 75]}\n",
    "bag_params = {'classifier__n_estimators': [5, 10, 20]}\n",
    "voting_params = {'classifier__voting': ['hard', 'soft']}\n",
    "\n",
    "params_dict = {\n",
    "    'K-Nearest Neighbors': knn_params,\n",
    "    'Logistic Regression': log_reg_params,\n",
    "    'Random Forest': rf_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'Bagging': bag_params,\n",
    "    'Voting': voting_params\n",
    "}\n",
    "\n",
    "# Initialize results dictionary for tuned models\n",
    "tuned_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through classifiers for tuning\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', clf)])\n",
    "    \n",
    "    # Create GridSearchCV object\n",
    "    grid = GridSearchCV(pipeline, params_dict[name], cv=5)\n",
    "    \n",
    "    # Fit the model\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator and predict\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    y_pred = pipeline.predict(X_test) \n",
    "    \n",
    "    # Compute metrics\n",
    "    precision = precision_score(y_true, y_pred, pos_label='yes')\n",
    "    recall = recall_score(y_true, y_pred, pos_label='yes')\n",
    "    f1 = f1_score(y_true, y_pred, pos_label='yes')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    # Store results\n",
    "    tuned_results[name] = {\n",
    "        'Best Params': grid.best_params_,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Time (s)': elapsed_time\n",
    "    }\n",
    "\n",
    "# Convert results to DataFrame for easier viewing\n",
    "tuned_results_df = pd.DataFrame(tuned_results).T\n",
    "print(tuned_results_df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
